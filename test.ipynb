{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-17T06:36:54.221712Z",
     "start_time": "2025-10-17T06:36:50.897905Z"
    }
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    from skimage.feature.texture import greycomatrix, greycoprops\n",
    "except ImportError:\n",
    "    from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from typing import List, Tuple\n",
    "\n",
    "# --------------------------\n",
    "# Feature extraction utils\n",
    "# --------------------------\n",
    "\n",
    "def read_image_rgb(path: str):\n",
    "    \"\"\"Read image using OpenCV and return as RGB uint8 array.\"\"\"\n",
    "    bgr = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if bgr is None:\n",
    "        raise FileNotFoundError(f\"Cannot read image: {path}\")\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    return rgb\n",
    "\n",
    "def extract_hsv_histogram(img_rgb: np.ndarray, bins=(16,8,8)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute normalized HSV histogram (flattened).\n",
    "    bins: tuple (H_bins, S_bins, V_bins)\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0,1,2], None, bins,\n",
    "                        [0,180,0,256,0,256])  # OpenCV H range 0-180\n",
    "    hist = hist.flatten().astype('float32')\n",
    "    # L1 normalize\n",
    "    s = hist.sum()\n",
    "    if s > 0:\n",
    "        hist /= s\n",
    "    return hist\n",
    "\n",
    "def extract_hsv_stats(img_rgb: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute mean, std, skewness, kurtosis for each HSV channel.\n",
    "    Returns 12 values (4 stats Ã— 3 channels).\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV).astype('float32')\n",
    "    stats = []\n",
    "    for ch in range(3):\n",
    "        vals = hsv[:,:,ch].flatten()\n",
    "        stats.append(vals.mean())\n",
    "        stats.append(vals.std(ddof=0))\n",
    "        stats.append(skew(vals))\n",
    "        stats.append(kurtosis(vals))\n",
    "    return np.array(stats, dtype='float32')\n",
    "\n",
    "def extract_glcm_features(img_rgb: np.ndarray, distances=[1], levels=16) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute GLCM features averaged over angles (0,45,90,135).\n",
    "    Returns contrast, correlation, energy, homogeneity (4 values).\n",
    "    We quantize grayscale image to `levels` (e.g., 16).\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    # Quantize to levels (0..levels-1)\n",
    "    if gray.dtype != np.uint8:\n",
    "        gray = gray.astype('uint8')\n",
    "    q = (gray.astype('float32') * (levels - 1) / 255.0).round().astype('uint8')\n",
    "    # angles in radians\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    # compute glcm (skimage expects values in [0, levels-1])\n",
    "    # Use symmetric and normed so values are comparable\n",
    "    G = greycomatrix(q, distances=distances, angles=angles, levels=levels,\n",
    "                     symmetric=True, normed=True)\n",
    "    # props to extract\n",
    "    props = []\n",
    "    for prop in ['contrast', 'correlation', 'energy', 'homogeneity']:\n",
    "        p = greycoprops(G, prop)  # shape (len(distances), len(angles))\n",
    "        # average across distances and angles\n",
    "        props.append(p.mean())\n",
    "    return np.array(props, dtype='float32')\n",
    "\n",
    "def extract_shape_features(img_rgb: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute shape features based on Otsu threshold:\n",
    "    - area (largest contour)\n",
    "    - perimeter\n",
    "    - aspect_ratio (w/h of bounding box)\n",
    "    - extent (area / bbox_area)\n",
    "    - solidity (area / convex_hull_area)\n",
    "    - circularity (4*pi*area / perimeter^2)\n",
    "    Returns 6 values.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    # Otsu threshold\n",
    "    try:\n",
    "        th = threshold_otsu(gray)\n",
    "        _, bw = cv2.threshold(gray, int(th), 255, cv2.THRESH_BINARY)\n",
    "    except Exception:\n",
    "        # fallback to Otsu via OpenCV\n",
    "        _, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # find contours\n",
    "    contours, _ = cv2.findContours(bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        # return zeros if nothing found\n",
    "        return np.zeros(6, dtype='float32')\n",
    "\n",
    "    # pick largest contour by area\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    area = cv2.contourArea(c)\n",
    "    perimeter = cv2.arcLength(c, True)\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    bbox_area = w * h if (w*h) > 0 else 1.0\n",
    "    aspect_ratio = float(w) / float(h) if h > 0 else 0.0\n",
    "    extent = float(area) / float(bbox_area)\n",
    "    # solidity = area / convexHullArea\n",
    "    hull = cv2.convexHull(c)\n",
    "    hull_area = cv2.contourArea(hull) if hull is not None else 0.0\n",
    "    solidity = float(area) / hull_area if hull_area > 0 else 0.0\n",
    "    # circularity\n",
    "    circularity = 4.0 * np.pi * area / (perimeter * perimeter) if perimeter > 0 else 0.0\n",
    "\n",
    "    feats = np.array([area, perimeter, aspect_ratio, extent, solidity, circularity], dtype='float32')\n",
    "    return feats\n",
    "\n",
    "def extract_features_from_path(path: str, config: str = 'C') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract feature vector for an image path.\n",
    "    config: 'A' -> color only, 'B' -> glcm only, 'C' -> combined (color+glcm+shape)\n",
    "    \"\"\"\n",
    "    img = read_image_rgb(path)\n",
    "    feats = []\n",
    "    if config in ('A', 'C'):\n",
    "        hist = extract_hsv_histogram(img, bins=(16,8,8))\n",
    "        stats = extract_hsv_stats(img)\n",
    "        feats.append(hist)\n",
    "        feats.append(stats)\n",
    "    if config in ('B', 'C'):\n",
    "        glcm = extract_glcm_features(img, distances=[1], levels=16)\n",
    "        feats.append(glcm)\n",
    "    if config == 'C':\n",
    "        shape = extract_shape_features(img)\n",
    "        feats.append(shape)\n",
    "    # concatenate\n",
    "    if feats:\n",
    "        return np.concatenate(feats).astype('float32')\n",
    "    else:\n",
    "        return np.array([], dtype='float32')\n",
    "\n",
    "# --------------------------\n",
    "# Indexing and searching\n",
    "# --------------------------\n",
    "\n",
    "def build_index(db_folder: str, config: str = 'C') -> Tuple[List[str], np.ndarray, StandardScaler]:\n",
    "    \"\"\"\n",
    "    Build index: iterate files in db_folder, extract features based on config.\n",
    "    Returns: list of file paths (order), feature_matrix (n_samples x n_features), fitted StandardScaler\n",
    "    \"\"\"\n",
    "    img_paths = []\n",
    "    for fn in sorted(os.listdir(db_folder)):\n",
    "        full = os.path.join(db_folder, fn)\n",
    "        if os.path.isfile(full):\n",
    "            img_paths.append(full)\n",
    "\n",
    "    features = []\n",
    "    valid_paths = []\n",
    "    for p in img_paths:\n",
    "        try:\n",
    "            fv = extract_features_from_path(p, config=config)\n",
    "            if fv.size == 0:\n",
    "                continue\n",
    "            features.append(fv)\n",
    "            valid_paths.append(p)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {p}: {e}\")\n",
    "\n",
    "    if not features:\n",
    "        raise RuntimeError(\"No features extracted from db_folder. Check images and paths.\")\n",
    "\n",
    "    X = np.vstack(features)  # shape (n_samples, n_features)\n",
    "\n",
    "    # Standardize features (fit on DB)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    return valid_paths, X_scaled, scaler\n",
    "\n",
    "def search_query(query_path: str, db_paths: List[str], X_scaled: np.ndarray, scaler: StandardScaler,\n",
    "                 config: str = 'C', metric: str = 'cosine', topk: int = 5) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Extract features for query, scale with scaler, compute distances to DB, return topk (path, distance).\n",
    "    metric: 'cosine' or 'euclidean'\n",
    "    \"\"\"\n",
    "    qfv = extract_features_from_path(query_path, config=config)\n",
    "    if qfv.size == 0:\n",
    "        raise RuntimeError(\"Query feature vector is empty.\")\n",
    "    qfv_scaled = scaler.transform(qfv.reshape(1, -1))\n",
    "    # compute pairwise distances between query and DB\n",
    "    dists = pairwise_distances(qfv_scaled, X_scaled, metric=metric).flatten()\n",
    "    idx_sorted = np.argsort(dists)  # ascending (smallest = most similar)\n",
    "    results = [(db_paths[i], float(dists[i])) for i in idx_sorted[:topk]]\n",
    "    return results\n",
    "\n",
    "# --------------------------\n",
    "# Utility: extract label (for evaluation)\n",
    "# --------------------------\n",
    "\n",
    "def filename_label(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract label from filename. Adjust this function to your dataset naming scheme.\n",
    "    Default: take filename before first underscore or dash or first token.\n",
    "    \"\"\"\n",
    "    fn = os.path.basename(path)\n",
    "    name = os.path.splitext(fn)[0]\n",
    "    # common separators: underscore, dash\n",
    "    for sep in ['_', '-']:\n",
    "        if sep in name:\n",
    "            return name.split(sep)[0]\n",
    "    # fallback: whole name\n",
    "    return name\n",
    "\n",
    "def precision_at_k(results: List[Tuple[str, float]], query_path: str, k: int = 5) -> float:\n",
    "    qlabel = filename_label(query_path)\n",
    "    topk = results[:k]\n",
    "    hits = sum(1 for p, _ in topk if filename_label(p) == qlabel)\n",
    "    return hits / k\n",
    "\n",
    "# --------------------------\n",
    "# Visualization\n",
    "# --------------------------\n",
    "\n",
    "def show_search_results(query_path: str, results: List[Tuple[str, float]], figsize=(14,4)):\n",
    "    \"\"\"Show query image and top-k results horizontally with distances.\"\"\"\n",
    "    k = len(results)\n",
    "    plt.figure(figsize=figsize)\n",
    "    # show query at left\n",
    "    plt.subplot(1, k+1, 1)\n",
    "    qimg = read_image_rgb(query_path)\n",
    "    plt.imshow(qimg)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Query\")\n",
    "    # show results\n",
    "    for i, (p, dist) in enumerate(results, start=2):\n",
    "        plt.subplot(1, k+1, i)\n",
    "        img = read_image_rgb(p)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Rank {i-1}\\nDist: {dist:.4f}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# Example usage\n",
    "# --------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # PUT YOUR PATHS HERE\n",
    "    DB_FOLDER = \"db\"       # folder with database images\n",
    "    QUERY_FOLDER = \"query\" # folder with query images\n",
    "\n",
    "    # Choose configuration: 'A' (color), 'B' (GLCM), 'C' (combined).\n",
    "    CONFIG = 'C'\n",
    "    METRIC = 'cosine'  # or 'euclidean'\n",
    "\n",
    "    # Build index (extract features for DB)\n",
    "    print(\"Building index...\")\n",
    "    db_paths, X_scaled, scaler = build_index(DB_FOLDER, config=CONFIG)\n",
    "    print(f\"Indexed {len(db_paths)} images, feature dim = {X_scaled.shape[1]}\")\n",
    "\n",
    "    # Loop through queries and display results\n",
    "    for qfn in sorted(os.listdir(QUERY_FOLDER)):\n",
    "        qpath = os.path.join(QUERY_FOLDER, qfn)\n",
    "        if not os.path.isfile(qpath):\n",
    "            continue\n",
    "        print(f\"\\nSearching for query: {qpath}\")\n",
    "        results = search_query(qpath, db_paths, X_scaled, scaler, config=CONFIG, metric=METRIC, topk=5)\n",
    "        # print results\n",
    "        for rank, (p, d) in enumerate(results, start=1):\n",
    "            print(f\"Rank {rank}: {os.path.basename(p)}  Dist={d:.6f}\")\n",
    "        # show images\n",
    "        show_search_results(qpath, results)\n",
    "        # compute Precision@5 if labels are available\n",
    "        p5 = precision_at_k(results, qpath, k=5)\n",
    "        print(f\"Precision@5 = {p5:.2f}\")\n"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'greycomatrix' from 'skimage.feature' (C:\\Users\\magnu\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\skimage\\feature\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mskimage\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfeature\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtexture\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m greycomatrix, greycoprops\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'greycomatrix' from 'skimage.feature.texture' (C:\\Users\\magnu\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\skimage\\feature\\texture.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      6\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mskimage\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfeature\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtexture\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m greycomatrix, greycoprops\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mskimage\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfeature\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m greycomatrix, greycoprops\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mskimage\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfilters\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m threshold_otsu\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mstats\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m skew, kurtosis\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'greycomatrix' from 'skimage.feature' (C:\\Users\\magnu\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\skimage\\feature\\__init__.py)"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
